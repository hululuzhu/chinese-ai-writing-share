{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Updated 2021 Transformer AI Writing Demo 06/2021",
      "provenance": [],
      "collapsed_sections": [
        "ipB2xHkn-asg",
        "4R1I78Xu--Jx"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hululuzhu/chinese-ai-writing-share/blob/main/inferencer/2021_transformer_supervised_AI_Writing_Demo_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to Google Drive to reference [models and vocabs](https://drive.google.com/drive/folders/1d5vk9nrse4lJ55wb5zsW2wgodkwWb-V2?usp=sharing) and Initialize\n",
        "\n",
        "- Run all code and test examples by replacing chars\n",
        "- Please note I set topk=1 and tempature=1.0 for reproduce, play with different inference params when you run it."
      ],
      "metadata": {
        "id": "ipB2xHkn-asg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "4R1I78Xu--Jx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install keras-transformer &> /dev/null\n",
        "os.environ['TF_KERAS'] = '1'\n",
        "from keras_transformer import get_model, decode, get_custom_objects\n",
        "import tensorflow as tf"
      ],
      "outputs": [],
      "metadata": {
        "id": "hCg7PwbO-4n5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Configs"
      ],
      "metadata": {
        "id": "H6SM55DRH-H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive if you have your copies of model/configs\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yOXsqTQWtThU",
        "outputId": "6fb87c5f-d471-43fe-c6c1-3b6b17180bf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Copy https://drive.google.com/drive/folders/1d5vk9nrse4lJ55wb5zsW2wgodkwWb-V2 and match your local dir here\n",
        "MODEL_DIR = 'drive/MyDrive/ML/Models/szhu_public_062021/'"
      ],
      "outputs": [],
      "metadata": {
        "id": "dujcdkTu_C6h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 如出错，请拷贝最开始介绍的那个Google Drive的所有文件，并mount到colab\n",
        "!ls {MODEL_DIR}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "couplet_model_config.pickle  couplet_vocab.pickle      poem_model.h5\n",
            "couplet_model.h5\t     poem_model_config.pickle  poem_vocab.pickle\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq-x1MtE-UUY",
        "outputId": "59e7d1ee-50c0-4f5e-b5cf-3a84e6c73ac2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "with open(os.path.join(MODEL_DIR, 'couplet_model_config.pickle'), 'rb') as handle:\n",
        "  couplet_model_config = pickle.load(handle)\n",
        "with open(os.path.join(MODEL_DIR, 'couplet_vocab.pickle'), 'rb') as handle:\n",
        "  couplet_vocab_dict = pickle.load(handle)\n",
        "with open(os.path.join(MODEL_DIR, 'poem_model_config.pickle'), 'rb') as handle:\n",
        "  poem_model_config = pickle.load(handle)\n",
        "with open(os.path.join(MODEL_DIR, 'poem_vocab.pickle'), 'rb') as handle:\n",
        "  poem_vocab_dict = pickle.load(handle)"
      ],
      "outputs": [],
      "metadata": {
        "id": "uze7aFdx_Kji"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "rev_couplet_vocab_dict = {v: k for k, v in couplet_vocab_dict.items()}\n",
        "rev_poem_vocab_dict = {v: k for k, v in poem_vocab_dict.items()}"
      ],
      "outputs": [],
      "metadata": {
        "id": "-dkvK17OEX78"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "assert 9133 == len(couplet_vocab_dict)\n",
        "assert 11289 == len(poem_vocab_dict)"
      ],
      "outputs": [],
      "metadata": {
        "id": "dMgyN03D_njJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize models and sup methods"
      ],
      "metadata": {
        "id": "CPNN8DGa_3Ro"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "couplet_model = get_model(\n",
        "    embed_weights=np.random.random((len(couplet_vocab_dict),\n",
        "                                    couplet_model_config['embed_dim'])),\n",
        "    **couplet_model_config)\n",
        "couplet_model.load_weights(os.path.join(MODEL_DIR, 'couplet_model.h5'))\n",
        "\n",
        "\n",
        "poem_model = get_model(\n",
        "    embed_weights=np.random.random((len(poem_vocab_dict),\n",
        "                                    poem_model_config['embed_dim'])),\n",
        "    **poem_model_config)\n",
        "poem_model.load_weights(os.path.join(MODEL_DIR, 'poem_model.h5'))"
      ],
      "outputs": [],
      "metadata": {
        "id": "-3EqiHb9_42B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "START_TOKEN_ID = poem_vocab_dict['<START>']\n",
        "END_TOKEN_ID = poem_vocab_dict['<END>']\n",
        "PAD_TOKEN_ID = poem_vocab_dict['<PAD>']\n",
        "\n",
        "COUPLET_MAX_SEQ_LEN = 34\n",
        "POEM_MAX_INPUT_SEQ = 14\n",
        "POEM_MAX_OUTPUT_SEQ = 66\n",
        "\n",
        "def couplet_inference(pre_couplet, top_k=1, temperature=1.0):\n",
        "  out = \"上: \" + pre_couplet + \"\\n\"\n",
        "  in_vector = [START_TOKEN_ID]\n",
        "  for c in pre_couplet:\n",
        "    in_vector.append(couplet_vocab_dict[c])\n",
        "  in_vector.append(END_TOKEN_ID)\n",
        "  decoded = decode(\n",
        "      couplet_model,\n",
        "      [in_vector],\n",
        "      start_token=couplet_vocab_dict['<START>'],\n",
        "      end_token=couplet_vocab_dict['<END>'],\n",
        "      pad_token=couplet_vocab_dict['<PAD>'],\n",
        "      max_len=COUPLET_MAX_SEQ_LEN,\n",
        "      top_k=top_k,\n",
        "      temperature=temperature,\n",
        "  )\n",
        "  for i in range(len(decoded)):\n",
        "    out += '下: ' + ''.join(map(lambda x: rev_couplet_vocab_dict[x],\n",
        "                       decoded[i][1:-1]))\n",
        "  print(out)\n",
        "\n",
        "def poem_encode(raw_text, is_decode_input, is_decode_output):\n",
        "  assert not (is_decode_input and is_decode_output)\n",
        "  output = []\n",
        "  if not is_decode_output:\n",
        "    output.append(START_TOKEN_ID)\n",
        "  for c in raw_text:\n",
        "    output.append(poem_vocab_dict[c])\n",
        "  output.append(END_TOKEN_ID)\n",
        "  # padding\n",
        "  total_size = POEM_MAX_OUTPUT_SEQ if is_decode_input or is_decode_output else POEM_MAX_INPUT_SEQ\n",
        "  for i in range(total_size - len(output)):\n",
        "    output.append(PAD_TOKEN_ID)\n",
        "  return output\n",
        "\n",
        "def poem_decode(token_ids):\n",
        "  output = \"\"\n",
        "  for token_id in token_ids:\n",
        "    if token_id > 2:\n",
        "      output += rev_poem_vocab_dict[token_id]\n",
        "    elif token_id == 0:\n",
        "      break\n",
        "  return output\n",
        "\n",
        "def poem_inference(title, top_k=1, temperature=1.0):\n",
        "  out = \"标题: \" + title + \"\\n\"\n",
        "  decoded = decode(\n",
        "      poem_model,\n",
        "      poem_encode(title, False, False),\n",
        "      start_token=START_TOKEN_ID,\n",
        "      end_token=END_TOKEN_ID,\n",
        "      pad_token=PAD_TOKEN_ID,\n",
        "      max_len=POEM_MAX_OUTPUT_SEQ,\n",
        "      top_k=top_k,\n",
        "      temperature=temperature,\n",
        "  )\n",
        "  out += \"正文: \" + poem_decode(decoded)\n",
        "  print(out)\n",
        "\n",
        "poem_inference('秋思')\n",
        "couplet_inference('欢天喜地度佳节')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "标题: 秋思\n",
            "正文: 秋风吹雨过，秋色满江城。一叶无人到，千山有客情。\n",
            "上: 欢天喜地度佳节\n",
            "下: 举国迎春贺新年\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hrRPle-D89G",
        "outputId": "6c0dc8ad-1f24-4264-93a2-e690a8121036"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "zIrhA85CHWcI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for pre in ['欢天喜地度佳节', '不待鸣钟已汗颜，重来试手竟何艰',\n",
        "            '当年欲跃龙门去，今日真披马革还', '载歌在谷']:\n",
        "  couplet_inference(pre, top_k=1, temperature=1.0)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "上: 欢天喜地度佳节\n",
            "下: 举国迎春贺新年\n",
            "上: 不待鸣钟已汗颜，重来试手竟何艰\n",
            "下: 只缘沧海常风雨，再去翻身只等闲\n",
            "上: 当年欲跃龙门去，今日真披马革还\n",
            "下: 此际重逢凤阙来，明朝再赋凤凰鸣\n",
            "上: 载歌在谷\n",
            "下: 如醉如痴\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKkbnDPHGbGo",
        "outputId": "e2f249cb-137e-4f95-9633-42c06b345f2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "couplet_inference('愿新年胜旧年', top_k=1, temperature=1.0)"
      ],
      "metadata": {
        "id": "170u9ESXNFYd",
        "outputId": "b5b09a39-7cc7-4643-d950-bd5042e40930",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "上: 愿新年胜旧年\n",
            "下: 再造福如今朝\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for t in ['秋思', '百度', '湾区春日之谜', '自由而无用之灵魂']:\n",
        "  poem_inference(t, top_k=1, temperature=1.0)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "标题: 秋思\n",
            "正文: 秋风吹雨过，秋色满江城。一叶无人到，千山有客情。\n",
            "标题: 百度\n",
            "正文: 百尺孤城上，千金万里中。山川无限水，水石有余风。\n",
            "标题: 湾区春日之谜\n",
            "正文: 春风吹雨不成秋，春色如何一日休。不是春光无处着，只应春色是人愁。\n",
            "标题: 自由而无用之灵魂\n",
            "正文: 我生不知，不识不知。我之不知，我之不知。我亦不知，不如不知。我亦不知，不知何爲。\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx-xnGr_E--u",
        "outputId": "a24007d8-5f70-4691-d95a-a5d8fc05f860"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poem_inference('山雨', top_k=1, temperature=1.0)"
      ],
      "metadata": {
        "id": "jTjbcZjTOCD8",
        "outputId": "b264d92a-67e0-4295-a7f5-9651aa545ab3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "标题: 山雨\n",
            "正文: 山雨不可见，山云无限情。山林无处觅，山色有时生。\n"
          ]
        }
      ]
    }
  ]
}